{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    300000 non-null  int64  \n",
      " 1   Brand                 290295 non-null  object \n",
      " 2   Material              291653 non-null  object \n",
      " 3   Size                  293405 non-null  object \n",
      " 4   Compartments          300000 non-null  float64\n",
      " 5   Laptop_Compartment    292556 non-null  object \n",
      " 6   Waterproof            292950 non-null  object \n",
      " 7   Style                 292030 non-null  object \n",
      " 8   Color                 290050 non-null  object \n",
      " 9   Weight_Capacity_(kg)  299862 non-null  float64\n",
      " 10  Price                 300000 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 25.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['Brand', 'Material','Size', 'Laptop_Compartment','Waterproof','Style','Color']\n",
    "\n",
    "def preprocess(df):\n",
    "    data_processed = df.copy()\n",
    "\n",
    "    weight_imputer=SimpleImputer(strategy='median')\n",
    "    weight_imputer.fit(df[['Weight_Capacity_(kg)']])\n",
    "\n",
    "    frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    frequent_imputer.fit(df[cat_cols])\n",
    "\n",
    "    average_imputer=SimpleImputer(strategy='mean')\n",
    "    average_imputer.fit(df[['Compartments']])\n",
    "\n",
    "\n",
    "    data_processed[['Weight_Capacity_(kg)']]=weight_imputer.transform(data_processed[['Weight_Capacity_(kg)']])\n",
    "    data_processed[cat_cols]=frequent_imputer.transform(data_processed[cat_cols])\n",
    "    data_processed[['Compartments']] = average_imputer.transform(data_processed[['Compartments']])\n",
    "\n",
    "    data_processed = pd.get_dummies(data_processed, columns=cat_cols, drop_first=False, dtype=int).copy()\n",
    "\n",
    "    weight_scaler = StandardScaler()\n",
    "    weight_scaler.fit(df[['Weight_Capacity_(kg)']])\n",
    "    data_processed[['Weight_Capacity_(kg)']] = weight_scaler.transform(data_processed[['Weight_Capacity_(kg)']])\n",
    "    \n",
    "    return data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = preprocess(df)\n",
    "Y = processed_train['Price']\n",
    "X = processed_train.drop(columns=['id', 'Price'], axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import optuna\n",
    "\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": 70,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 0.01, 1),\n",
    "        \"subsample\": trial.suggest_loguniform(\"subsample\", 0.1, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.1, 1),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.1, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 1),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 1)\n",
    "    }\n",
    "\n",
    "    xgb=XGBRegressor(**params, enable_categorical=True)\n",
    "    xgb.fit(X_train,Y_train)\n",
    "    Y_pred = xgb.predict(X_test)\n",
    "\n",
    "    return root_mean_squared_error(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_xgb = optuna.create_study(direction='minimize')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_xgb.optimize(objective_xgboost, n_trials=50, show_progress_bar=True)\n",
    "best_params_xgb = study_xgb.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.columns = df_test.columns.str.replace(' ', '_')\n",
    "model_xgb = XGBRegressor(**best_params_xgb)\n",
    "model_xgb.fit(X_train, Y_train)\n",
    "\n",
    "test_id_col = df_test.id\n",
    "df_test = df_test.drop('id',axis=1)\n",
    "df_test_preproc = preprocess(df_test)\n",
    "\n",
    "\n",
    "test_predicted = model_xgb.predict(df_test_preproc)\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_id_col,\n",
    "    'Price': test_predicted\n",
    "})\n",
    "submission.to_csv('submission-without-pipelines.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
